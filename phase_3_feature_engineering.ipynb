{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e609b2a",
   "metadata": {},
   "source": [
    "- load the data from the data folder for the analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e43d14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data\\phase_2_titanic_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f0a26",
   "metadata": {},
   "source": [
    "This standardization centers the values around zero with unit variance.\n",
    "$$z = \\frac{x-mean}{{std}_{dev}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca445f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# df['age_scaled'] = scaler.fit_transform(df[['age']])\n",
    "# df['fare_scaled'] = scaler.fit_transform(df[['fare']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba35d5b",
   "metadata": {},
   "source": [
    "#### ðŸ”¹ 2. Normalization (Min-Max Scaling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f26b5",
   "metadata": {},
   "source": [
    "This transforms values to a [0, 1] range\n",
    "$$x' = \\frac{x - min(x)}{max(x) - min(x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18ba1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['age_norm'] = scaler.fit_transform(df[['age']])\n",
    "df['fare_norm'] = scaler.fit_transform(df[['fare']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356dcea",
   "metadata": {},
   "source": [
    "\n",
    "We need to convert strings to numbers.\n",
    "\n",
    "#### ðŸ”¹ 1. Label Encoding (e.g. for binary columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "637dec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex_encoded",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d38a5de1-249b-4187-b158-5beb9f52b135",
       "rows": [
        [
         "0",
         "1"
        ],
        [
         "1",
         "0"
        ],
        [
         "2",
         "0"
        ],
        [
         "3",
         "0"
        ],
        [
         "4",
         "1"
        ],
        [
         "5",
         "1"
        ],
        [
         "6",
         "1"
        ],
        [
         "7",
         "1"
        ],
        [
         "8",
         "0"
        ],
        [
         "9",
         "0"
        ],
        [
         "10",
         "0"
        ],
        [
         "11",
         "0"
        ],
        [
         "12",
         "1"
        ],
        [
         "13",
         "1"
        ],
        [
         "14",
         "0"
        ],
        [
         "15",
         "0"
        ],
        [
         "16",
         "1"
        ],
        [
         "17",
         "1"
        ],
        [
         "18",
         "0"
        ],
        [
         "19",
         "0"
        ],
        [
         "20",
         "1"
        ],
        [
         "21",
         "1"
        ],
        [
         "22",
         "0"
        ],
        [
         "23",
         "1"
        ],
        [
         "24",
         "0"
        ],
        [
         "25",
         "0"
        ],
        [
         "26",
         "1"
        ],
        [
         "27",
         "0"
        ],
        [
         "28",
         "1"
        ],
        [
         "29",
         "1"
        ],
        [
         "30",
         "0"
        ],
        [
         "31",
         "1"
        ],
        [
         "32",
         "1"
        ],
        [
         "33",
         "1"
        ],
        [
         "34",
         "1"
        ],
        [
         "35",
         "0"
        ],
        [
         "36",
         "0"
        ],
        [
         "37",
         "0"
        ],
        [
         "38",
         "0"
        ],
        [
         "39",
         "1"
        ],
        [
         "40",
         "0"
        ],
        [
         "41",
         "0"
        ],
        [
         "42",
         "1"
        ],
        [
         "43",
         "1"
        ],
        [
         "44",
         "1"
        ],
        [
         "45",
         "0"
        ],
        [
         "46",
         "1"
        ],
        [
         "47",
         "1"
        ],
        [
         "48",
         "0"
        ],
        [
         "49",
         "1"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 679
       }
      },
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "674    0\n",
       "675    0\n",
       "676    0\n",
       "677    1\n",
       "678    1\n",
       "Name: sex_encoded, Length: 679, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['sex_encoded'] = le.fit_transform(df['sex'])  # male=1, female=0\n",
    "df['sex_encoded']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c6924e",
   "metadata": {},
   "source": [
    "\n",
    "#### ðŸ”¹ 2. One-Hot Encoding (e.g. for columns like `embarked`, `class`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fa2a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['embarked', 'class'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e4e25",
   "metadata": {},
   "source": [
    "\n",
    "### âœ… Step 3: Feature Selection (Basic)\n",
    "Remove less useful features or redundant columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "401482a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sibsp', 'parch', 'alone', 'age_norm',\n",
       "       'fare_norm', 'sex_encoded', 'embarked_Q', 'embarked_S', 'class_Second',\n",
       "       'class_Third'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns not useful for prediction\n",
    "df = df.drop(columns=['sex', 'age', 'fare', 'deck', 'embark_town', 'who', 'alive', 'adult_male'])\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd0f73",
   "metadata": {},
   "source": [
    "\n",
    "You can also use `df.corr()` to check correlation between features and remove highly correlated ones if needed.\n",
    "\n",
    "---\n",
    "\n",
    "When you're done with this step, weâ€™ll move to **Phase 4: Data Splitting** (final part before modeling). Let me know!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fe49300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/phase_3_titanic_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
